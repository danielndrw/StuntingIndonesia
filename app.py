# -*- coding: utf-8 -*-
"""app

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1zYTQrzw4n6dTT3PZ44hCY9qsoNeg4k8d
"""

# ================================================================
# STREAMLIT APP — DASHBOARD STUNTING INDONESIA (SINKRON TRAINING)
# ================================================================

import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import joblib, os, json, requests, re

# -----------------------------
# CONFIG
# -----------------------------
st.set_page_config(page_title="📊 Dashboard Stunting Indonesia", layout="wide")
st.title("🇮🇩 Dashboard Analisis Stunting Indonesia")
st.markdown("### Clustering, Klasifikasi, dan Prediksi Stunting berbasis Data Sosial Ekonomi")
st.markdown("---")

# ================================================================
# 0) UTIL: KOORDINAT, NORMALISASI PROVINSI, GEOJSON & PETA
# ================================================================
PROV_COORDS = {
    "ACEH": (4.70, 96.75), "SUMATERA UTARA": (2.11, 99.55), "SUMATERA BARAT": (-0.74, 100.80),
    "RIAU": (0.29, 101.71), "KEPULAUAN RIAU": (0.92, 104.45), "JAMBI": (-1.61, 103.61),
    "SUMATERA SELATAN": (-3.32, 104.91), "BENGKULU": (-3.58, 102.35), "LAMPUNG": (-4.56, 105.41),
    "KEP. BANGKA BELITUNG": (-2.74, 106.44), "BANTEN": (-6.41, 106.06), "DKI JAKARTA": (-6.17, 106.83),
    "JAWA BARAT": (-6.89, 107.64), "JAWA TENGAH": (-7.15, 110.14), "D I YOGYAKARTA": (-7.79, 110.37),
    "JAWA TIMUR": (-7.54, 112.24), "BALI": (-8.34, 115.09), "NUSA TENGGARA BARAT": (-8.65, 117.36),
    "NUSA TENGGARA TIMUR": (-8.66, 121.08), "KALIMANTAN BARAT": (-0.13, 111.10), "KALIMANTAN TENGAH": (-1.68, 113.38),
    "KALIMANTAN SELATAN": (-3.09, 115.28), "KALIMANTAN TIMUR": (0.54, 116.42), "KALIMANTAN UTARA": (2.84, 117.39),
    "SULAWESI UTARA": (1.49, 124.84), "GORONTALO": (0.70, 122.45), "SULAWESI TENGAH": (-1.43, 121.45),
    "SULAWESI BARAT": (-2.84, 119.23), "SULAWESI SELATAN": (-3.67, 119.97), "SULAWESI TENGGARA": (-4.14, 122.17),
    "MALUKU": (-3.24, 130.15), "MALUKU UTARA": (1.57, 127.81), "PAPUA": (-4.27, 138.08),
    "PAPUA BARAT": (-1.34, 133.17), "PAPUA BARAT DAYA": (-0.88, 131.26),
    "PAPUA PEGUNUNGAN": (-4.10, 138.94), "PAPUA SELATAN": (-8.49, 140.40), "PAPUA TENGAH": (-3.36, 135.50)
}

def normalize_province(name: str) -> str | None:
    if pd.isna(name):
        return None
    s = str(name).upper().strip()
    s = re.sub(r"(PROVINSI|PROPINSI|DAERAH ISTIMEWA|KOTA|KAB\.?)", "", s)
    s = re.sub(r"[^A-Z\s]", "", s)
    s = re.sub(r"\s+", " ", s).strip()
    # samakan beberapa variasi umum
    aliases = {
        "DAERAH KHUSUS IBUKOTA JAKARTA": "DKI JAKARTA",
        "DI YOGYAKARTA": "D I YOGYAKARTA",
        "DAERAH ISTIMEWA YOGYAKARTA": "D I YOGYAKARTA",
        "KEPULAUAN BANGKA BELITUNG": "KEP. BANGKA BELITUNG",
        "BANGKA BELITUNG": "KEP. BANGKA BELITUNG",
    }
    return aliases.get(s, s)

@st.cache_data
def load_geojson():
    urls = [
        "https://raw.githubusercontent.com/superpikar/indonesia-geojson/master/indonesia-prov.geojson",
        "https://raw.githubusercontent.com/superpikar/indonesia-geojson/master/indonesia-province.geojson",
    ]
    for url in urls:
        try:
            r = requests.get(url, timeout=10)
            r.raise_for_status()
            gj = r.json()
            st.success("🌍 GeoJSON provinsi dimuat.")
            # validasi minimal
            if isinstance(gj, dict) and gj.get("type") == "FeatureCollection":
                return gj
        except Exception:
            continue
    st.warning("❌ GeoJSON gagal dimuat — akan fallback ke peta titik.")
    return None

def ensure_geo_columns(df_in: pd.DataFrame) -> pd.DataFrame:
    dfp = df_in.copy()
    dfp["Provinsi"] = dfp["Provinsi"].astype(str)
    dfp["prov_up"] = dfp["Provinsi"].map(normalize_province)
    dfp["lat"] = dfp["prov_up"].map(lambda p: PROV_COORDS.get(p, (np.nan, np.nan))[0])
    dfp["lon"] = dfp["prov_up"].map(lambda p: PROV_COORDS.get(p, (np.nan, np.nan))[1])
    # kalau semua NaN, pakai titik acak aman agar selalu tampil peta
    if dfp["lat"].isna().all():
        st.warning("⚠️ Nama provinsi tidak cocok dengan kamus koordinat — gunakan titik acak sementara.")
        dfp["lat"] = np.random.uniform(-7, 2, size=len(dfp))
        dfp["lon"] = np.random.uniform(100, 125, size=len(dfp))
    return dfp

def draw_map(df_map: pd.DataFrame, color_col: str, title: str, geojson=None,
             discrete: bool = False, discrete_map: dict | None = None):
    dfp = ensure_geo_columns(df_map)
    if geojson is not None and "Prediksi_Stunting_TahunDepan" not in color_col:
        # Usahakan choropleth bila key cocok; jika gagal, fallback ke scatter_geo
        try:
            fig = px.choropleth(
                dfp,
                geojson=geojson,
                featureidkey="properties.Propinsi",
                locations="Provinsi",
                color=color_col,
                color_discrete_map=(discrete_map or {}) if discrete else None,
                color_continuous_scale=None if discrete else "RdYlGn_r",
                title=title,
            )
            fig.update_geos(fitbounds="locations", visible=False)
            st.plotly_chart(fig, use_container_width=True)
            return
        except Exception:
            st.info("ℹ️ Choropleth gagal dicocokkan — fallback ke peta titik.")

    # Scatter geo (selalu sukses)
    if discrete:
        fig = px.scatter_geo(
            dfp, lat="lat", lon="lon", color=color_col, hover_name="Provinsi",
            color_discrete_map=discrete_map or {}, title=title
        )
    else:
        fig = px.scatter_geo(
            dfp, lat="lat", lon="lon", color=color_col, hover_name="Provinsi",
            color_continuous_scale="RdYlGn_r", title=title
        )
    fig.update_geos(fitbounds="locations", showcountries=True)
    st.plotly_chart(fig, use_container_width=True)

# ================================================================
# 1) LOAD DATA + (opsional) UPLOAD
# ================================================================
@st.cache_data
def load_default_data():
    return pd.read_excel("DATA_SUM_STUNTING.xlsx")

df = load_default_data()

st.sidebar.subheader("📤 Upload Dataset Baru (Opsional)")
up = st.sidebar.file_uploader("Pilih file Excel (.xlsx)", type=["xlsx"])
if up is not None:
    df = pd.read_excel(up)
    st.sidebar.success("✅ Data berhasil dimuat dari upload.")

# Validasi kolom minimal
required_cols = [
    'Provinsi','Years','Angka_Harapan_Hidup','Akses_Sanitasi_Layak','Akses_Air_Layak','Air_Kemasan',
    'IPM','Konsumsi_Pangan_Tidak_Cukup','Jumlah_KPM_Bansos','Anggaran_Bansos','Melek_Aksara',
    'Tingkat_Pengangguran','Imunisasi_Lengkap','Stunting','Lama_Sekolah','Garis_Kemiskinan_Makanan',
    'Kedalaman_Kemiskinan'
]
missing = [c for c in required_cols if c not in df.columns]
if missing:
    st.error(f"❌ Dataset tidak lengkap. Kolom hilang: {missing}")
    st.stop()

# ================================================================
# 2) FEATURE ENGINEERING (SAMA DENGAN TRAINING)
# ================================================================
def feature_engineering(dfin: pd.DataFrame) -> pd.DataFrame:
    d = dfin.copy()
    # kolom numeric: ubah string "1,23" -> 1.23 bila ada
    for c in d.columns:
        if d[c].dtype == object and c != "Provinsi":
            d[c] = d[c].replace(",", ".", regex=True)
            d[c] = pd.to_numeric(d[c], errors="ignore")

    # transformasi log
    d['log_Anggaran_Bansos'] = np.log1p(d['Anggaran_Bansos'])
    d['log_Jumlah_KPM_Bansos'] = np.log1p(d['Jumlah_KPM_Bansos'])
    d['log_Garis_Kemiskinan_Makanan'] = np.log1p(d['Garis_Kemiskinan_Makanan'])

    # interaksi & rasio
    d['IPM_x_LamaSekolah']   = d['IPM'] * d['Lama_Sekolah']
    d['AksesGabungan']        = d['Akses_Air_Layak'] * d['Akses_Sanitasi_Layak']
    d['Pengangguran_per_IPM'] = d['Tingkat_Pengangguran'] / (d['IPM'] + 1e-6)
    d['Bansos_per_KPM']       = np.where(d['Jumlah_KPM_Bansos'] > 0,
                                         d['Anggaran_Bansos'] / d['Jumlah_KPM_Bansos'],
                                         d['Anggaran_Bansos'])
    d['Konsumsi_vs_IPM']      = d['Konsumsi_Pangan_Tidak_Cukup'] / (d['IPM'] + 1e-6)

    # imputasi ringan (median) untuk jaga-jaga
    num_cols = d.select_dtypes(include=[np.number]).columns
    d[num_cols] = d[num_cols].fillna(d[num_cols].median())
    return d

df = feature_engineering(df)

# ================================================================
# 3) LOAD MODELS + METADATA FITUR (DARI TRAINING)
# ================================================================
@st.cache_resource
def load_models_and_meta():
    cluster = joblib.load("models/cluster_model.pkl")              # Pipeline(StandardScaler->KMeans)
    clf     = joblib.load("models/classification_model.pkl")       # RandomForestClassifier
    reg     = joblib.load("models/regression_model.pkl")           # XGBRegressor
    with open("models/expected_features.json", "r", encoding="utf-8") as f:
        meta = json.load(f)
    return cluster, clf, reg, meta

cluster_model, clf_model, reg_model, meta = load_models_and_meta()
FEATURES_BASE = meta.get("features_base", [])
FEATURES_ALL  = meta.get("features_all", [])

# ================================================================
# 4) GEOJSON (opsional, fallback ke scatter)
# ================================================================
geojson = load_geojson()

# ================================================================
# 5) SIDEBAR MODE
# ================================================================
st.sidebar.title("📁 Pilih Fitur Analisis")
mode = st.sidebar.radio(
    "Mode:",
    ["🧭 Clustering", "🏥 Klasifikasi Kesehatan", "📈 Prediksi Stunting (Tahun Depan)"]
)

# ================================================================
# 6) MODES
# ================================================================
if mode == "🧭 Clustering":
    st.subheader("🧭 Clustering Tingkat Kerentanan Stunting per Provinsi")
    try:
        Xc = df[FEATURES_BASE].copy()
        # cluster_model = Pipeline, jadi scaling sudah di dalam pipeline
        labels = cluster_model.predict(Xc)
        df_vis = df.copy()
        df_vis["Cluster"] = labels
        cluster_map = {0: "Sejahtera (Maju)", 1: "Sedang (Mainstream)", 2: "Rentan (Tertinggal)"}
        df_vis["Kategori_Cluster"] = df_vis["Cluster"].map(cluster_map)
        draw_map(
            df_vis, "Kategori_Cluster", "🗺️ Clustering Kerentanan Stunting",
            geojson=geojson, discrete=True,
            discrete_map={"Sejahtera (Maju)": "green", "Sedang (Mainstream)": "orange", "Rentan (Tertinggal)": "red"}
        )
    except Exception as e:
        st.error(f"❌ Gagal menjalankan clustering: {e}")

elif mode == "🏥 Klasifikasi Kesehatan":
    st.subheader("🏥 Klasifikasi Daerah Sehat vs Tidak Sehat")
    try:
        X = df[FEATURES_ALL].copy()
        y_pred = clf_model.predict(X)
        df_vis = df.copy()
        df_vis["Prediksi_Sehat"] = np.where(y_pred == 1, "Sehat", "Tidak Sehat")
        draw_map(
            df_vis, "Prediksi_Sehat", "🗺️ Daerah Sehat vs Tidak Sehat",
            geojson=geojson, discrete=True, discrete_map={"Sehat": "green", "Tidak Sehat": "red"}
        )
    except Exception as e:
        st.error(f"❌ Gagal menjalankan klasifikasi: {e}")

else:
    st.subheader("📈 Prediksi Stunting Tahun Depan")
    try:
        X = df[FEATURES_ALL].copy()
        y_next = reg_model.predict(X)
        df_vis = df.copy()
        df_vis["Prediksi_Stunting_TahunDepan"] = y_next
        draw_map(
            df_vis, "Prediksi_Stunting_TahunDepan", "🗺️ Prediksi Stunting Tahun Depan (%)",
            geojson=geojson, discrete=False
        )
        st.dataframe(
            df_vis[["Provinsi", "Prediksi_Stunting_TahunDepan"]]
            .sort_values("Prediksi_Stunting_TahunDepan")
            .reset_index(drop=True),
            use_container_width=True
        )
    except Exception as e:
        st.error(f"❌ Gagal menjalankan prediksi: {e}")